{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML_14.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMHqdm0/cAdB6SuzlltyeVC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujsaxena/AIML/blob/main/AIML_14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Gradient Boosting**\n",
        "\n",
        "Boosting is a method of converting a weak learner into a strong learner.\n",
        "\n",
        "These ideas built upon Leslie Valiant’s  work on distribution free or Probably Approximately Correct (PAC) learning, a framework for investigating the complexity of machine learning problems."
      ],
      "metadata": {
        "id": "vXUQNWWvBWFS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **AdaBoost the First Boosting Algorithm**\n",
        "\n",
        "The first realization of boosting that saw great success in application was Adaptive Boosting or AdaBoost for short.\n",
        "\n",
        "\"Boosting refers to this general problem of producing a very accurate prediction rule by combining rough and moderately inaccurate rules-of-thumb.\""
      ],
      "metadata": {
        "id": "rABw8G-eE6zw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The weak learners in AdaBoost are decision trees with a single split, called decision stumps for their shortness.\n",
        "\n",
        "AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns."
      ],
      "metadata": {
        "id": "q8UApD8HFc7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "“Boosting refers to this general problem of producing a very accurate prediction rule by combining rough and moderately inaccurate rules-of-thumb.” \n",
        "\n",
        "The weak learners in AdaBoost are decision trees with a single split, called decision stumps for their shortness. AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New weak learners are added sequentially that focus their training on the more difficult patterns. \n",
        "\n",
        "“This means that samples that are difficult to classify receive increasing larger weights until the algorithm identifies a model that correctly classifies these samples” \n",
        "\n",
        "Predictions are made by majority vote of the weak learners’ predictions, weighted by their individual accuracy. The most successful form of the AdaBoost algorithm was for binary classification problems and was called AdaBoost.M1. \n",
        "\n",
        "#**Generalization of AdaBoost as Gradient Boosting** \n",
        "\n",
        "AdaBoost and related algorithms were recast in a statistical framework first by Breiman calling them ARCing algorithms. \n",
        "\n",
        "“Arcing is an acronym for Adaptive Reweighting and Combining. Each step in an arcing algorithm consists of a weighted minimization followed by a recomputation of [the classifiers] and [weighted input].” \n",
        "\n",
        "This framework was further developed by Friedman and called Gradient Boosting Machines. Later called just gradient boosting or gradient tree boosting. The statistical framework cast boosting as a numerical optimization problem where the objective is to minimize the loss of the model by adding weak learners using a gradient descent like procedure. This class of algorithms were described as a stage-wise additive model. This is because one new weak learner is added at a time and existing weak learners in the model are frozen and left unchanged. \n",
        "\n",
        "“Note that this stagewise strategy is different from stepwise approaches that readjust previously entered terms when new ones are added.” \n",
        "\n",
        "The generalization allowed arbitrary differentiable loss functions to be used, expanding the technique beyond binary classification problems to support regression, multi-class classification and more. \n",
        "\n",
        "#**How Gradient Boosting Works** \n",
        "\n",
        "**Gradient boosting involves three elements:** \n",
        "\n",
        "A loss function to be optimized. \n",
        "\n",
        "A weak learner to make predictions. \n",
        "\n",
        "An additive model to add weak learners to minimize the loss function. \n",
        "\n",
        "1. Loss Function \n",
        "\n",
        "The loss function used depends on the type of problem being solved. It must be differentiable, but many standard loss functions are supported and you can define your own. For example, regression may use a squared error and classification may use logarithmic loss. A benefit of the gradient boosting framework is that a new boosting algorithm does not have to be derived for each loss function that may want to be used, instead, it is a generic enough framework that any differentiable loss function can be used. \n",
        "\n",
        "2. Weak Learner \n",
        "\n",
        "Decision trees are used as the weak learner in gradient boosting. Specifically regression trees are used that output real values for splits and whose output can be added together, allowing subsequent models outputs to be added and “correct” the residuals in the predictions. Trees are constructed in a greedy manner, choosing the best split points based on purity scores like Gini or to minimize the loss. Initially, such as in the case of AdaBoost, very short decision trees were used that only had a single split, called a decision stump. Larger trees can be used generally with 4-to-8 levels. \n",
        "\n",
        "“It is common to constrain the weak learners in specific ways, such as a maximum number of layers, nodes, splits or leaf nodes.” \n",
        "\n",
        "This is to ensure that the learners remain weak, but can still be constructed in a greedy manner. \n",
        "\n",
        "3. Additive Model \n",
        "\n",
        "Trees are added one at a time, and existing trees in the model are not changed. A gradient descent procedure is used to minimize the loss when adding trees. Traditionally, gradient descent is used to minimize a set of parameters, such as the coefficients in a regression equation or weights in a neural network. After calculating error or loss, the weights are updated to minimize that error. \n",
        "\n",
        "Instead of parameters, we have weak learner sub-models or more specifically decision trees. After calculating the loss, to perform the gradient descent procedure, we must add a tree to the model that reduces the loss (i.e. follow the gradient). We do this by parameterizing the tree, then modify the parameters of the tree and move in the right direction by (reducing the residual loss. Generally this approach is called functional gradient descent or gradient descent with functions. \n",
        "\n",
        "“One way to produce a weighted combination of classifiers which optimizes [the cost] is by gradient descent in function space” \n",
        "\n",
        "The output for the new tree is then added to the output of the existing sequence of trees in an effort to correct or improve the final output of the model. A fixed number of trees are added or training stops once loss reaches an acceptable level or no longer improves on an external validation dataset. \n",
        "\n",
        "#**Improvements to Basic Gradient Boosting** \n",
        "\n",
        "Gradient boosting is a greedy algorithm and can overfit a training dataset quickly. It can benefit from regularization methods that penalize various parts of the algorithm and generally improve the performance of the algorithm by reducing overfitting. \n",
        "\n",
        "Four enhancements to basic gradient boosting \n",
        "\n",
        "Tree Constraints \n",
        "\n",
        "Shrinkage \n",
        "\n",
        "Random sampling \n",
        "\n",
        "Penalized Learning \n",
        "\n",
        "1. Tree Constraints \n",
        "\n",
        "It is important that the weak learners have skill but remain weak. There are a number of ways that the trees can be constrained. A good general heuristic is that the more constrained tree creation is, the more trees you will need in the model, and the reverse, where less constrained individual trees, the fewer trees that will be required. Below are some constraints that can be imposed on the construction of decision trees: \n",
        "\n",
        "Number of trees, generally adding more trees to the model can be very slow to overfit. The advice is to keep adding trees until no further improvement is observed. \n",
        "\n",
        "Tree depth, deeper trees are more complex trees and shorter trees are preferred. Generally, better results are seen with 4-8 levels. \n",
        "\n",
        "Number of nodes or number of leaves, like depth, this can constrain the size of the tree, but is not constrained to a symmetrical structure if other constraints are used. \n",
        "\n",
        "Number of observations per split imposes a minimum constraint on the amount of training data at a training node before a split can be considered \n",
        "\n",
        "Minimim improvement to loss is a constraint on the improvement of any split added to a tree. \n",
        "\n",
        "2. Weighted Updates \n",
        "\n",
        "The predictions of each tree are added together sequentially. The contribution of each tree to this sum can be weighted to slow down the learning by the algorithm. This weighting is called a shrinkage or a learning rate. \n",
        "\n",
        "Each update is simply scaled by the value of the “learning rate parameter v” \n",
        "\n",
        "The effect is that learning is slowed down, in turn require more trees to be added to the model, in turn taking longer to train, providing a configuration trade-off between the number of trees and learning rate. Decreasing the value of v [the learning rate] increases the best value for M [the number of trees]. It is common to have small values in the range of 0.1 to 0.3, as well as values less than 0.1. \n",
        "\n",
        "Similar to a learning rate in stochastic optimization, shrinkage reduces the influence of each individual tree and leaves space for future trees to improve the model. \n",
        "\n",
        " \n",
        "\n",
        "3. Stochastic Gradient Boosting \n",
        "\n",
        "A big insight into bagging ensembles and random forest was allowing trees to be greedily created from subsamples of the training dataset. This same benefit can be used to reduce the correlation between the trees in the sequence in gradient boosting models. This variation of boosting is called stochastic gradient boosting. At each iteration a subsample of the training data is drawn at random (without replacement) from the full training dataset. The randomly selected subsample is then used, instead of the full sample, to fit the base learner. \n",
        "\n",
        "A few variants of stochastic boosting that can be used: \n",
        "\n",
        "Subsample rows before creating each tree. \n",
        "\n",
        "Subsample columns before creating each tree \n",
        "\n",
        "Subsample columns before considering each split. \n",
        "\n",
        "Generally, aggressive sub-sampling such as selecting only 50% of the data has shown to be beneficial. \n",
        "\n",
        "“According to user feedback, using column sub-sampling prevents over-fitting even more so than the traditional row sub-sampling” \n",
        "\n",
        "4. Penalized Gradient Boosting \n",
        "\n",
        "Additional constraints can be imposed on the parameterized trees in addition to their structure. Classical decision trees like CART are not used as weak learners, instead a modified form called a regression tree is used that has numeric values in the leaf nodes (also called terminal nodes). The values in the leaves of the trees can be called weights in some literature. As such, the leaf weight values of the trees can be regularized using popular regularization functions, such as: \n",
        "\n",
        "L1 regularization of weights. \n",
        "\n",
        "L2 regularization of weights. \n",
        "\n",
        "“The additional regularization term helps to smooth the final learnt weights to avoid over-fitting. Intuitively, the regularized objective will tend to select a model employing simple and predictive functions.” "
      ],
      "metadata": {
        "id": "tWpLdayFGueN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cat Boost**"
      ],
      "metadata": {
        "id": "IyFCMAqeF6nf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CatBoost is a machine learning algorithm that uses gradient boosting on decision trees. It is available as an open source library. Gradient boosting is one of the most powerful techniques for building predictive models. The idea of boosting came out of the idea of whether a weak learner can be modified to become better. \n",
        "\n",
        "A weak hypothesis or weak learner is defined as one whose performance is at least slightly better than random chance. These ideas built upon Leslie Valiant’s  work on distribution free or Probability Approximately Correct (PAC) learning, a framework for investigating the complexity of machine learning problems. Hypothesis boosting was the idea of filtering observations, leaving those observations that the weak learner can handle and focusing on developing new weak learns to handle the remaining difficult observations. \n"
      ],
      "metadata": {
        "id": "oYEk0LufGVtK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "“The idea is to use the weak learning method several times to get a succession of hypotheses, each one refocused on the examples that the previous ones found difficult and misclassified. … Note, however, it is not obvious at all how this can be done” \n"
      ],
      "metadata": {
        "id": "ZZAe2Rc7GY4T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bGZWeLUBTbi",
        "outputId": "7c6aad3c-9865-43db-d090-dbd88e335a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.0.4-cp37-none-manylinux1_x86_64.whl (76.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.1 MB 51 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor\n",
        "# Initialize data\n",
        "\n",
        "train_data = [[1, 4, 5, 6],\n",
        "              [4, 5, 6, 7],\n",
        "              [30, 40, 50, 60]]\n",
        "eval_data = [[4, 5, 6, 7]]\n",
        "\n",
        "train_labels = [-1,0 , 1]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=2,\n",
        "                          learning_rate=1,\n",
        "                          depth=2)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKOdM-fkLO5_",
        "outputId": "4e41883d-bb87-4a0a-dc9b-b48061f76a3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 46.3ms\tremaining: 46.3ms\n",
            "1:\tlearn: 0.4592793\ttotal: 47.2ms\tremaining: 0us\n",
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [30, 40, 50, 60]]\n",
        "eval_data = [[4, 5, 6, 7]]\n",
        "\n",
        "train_labels = [-1,0 , 1]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=2,\n",
        "                          learning_rate=1,\n",
        "                          depth=2)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PefwaEspMrrh",
        "outputId": "804801eb-285a-4d92-fbcd-015ad2ee04c9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 194us\tremaining: 194us\n",
            "1:\tlearn: 0.4592793\ttotal: 300us\tremaining: 0us\n",
            "[0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [30, 40, 50, 60]]\n",
        "eval_data = [[20, 21, 22, 23]]\n",
        "\n",
        "train_labels = [1,2 , 3]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=4,\n",
        "                          learning_rate=1,\n",
        "                          depth=8)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYwuk-1SM5w3",
        "outputId": "0de3e266-0331-4839-c321-c08d23b56aae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 188us\tremaining: 566us\n",
            "1:\tlearn: 0.4592793\ttotal: 354us\tremaining: 354us\n",
            "2:\tlearn: 0.3444595\ttotal: 3.19ms\tremaining: 1.06ms\n",
            "3:\tlearn: 0.2583446\ttotal: 3.54ms\tremaining: 0us\n",
            "[2.29296875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [30, 40, 50, 60]]\n",
        "eval_data = [[200, 300, 400, 500]]\n",
        "\n",
        "train_labels = [1,2 , 3]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=90,\n",
        "                          learning_rate=1,\n",
        "                          depth=4)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXAnf8_iNQxM",
        "outputId": "31c5606b-96df-4377-e2d1-2242cd747670"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 111us\tremaining: 9.95ms\n",
            "1:\tlearn: 0.4592793\ttotal: 1.59ms\tremaining: 70.1ms\n",
            "2:\tlearn: 0.3444595\ttotal: 2.13ms\tremaining: 61.8ms\n",
            "3:\tlearn: 0.2583446\ttotal: 2.5ms\tremaining: 53.8ms\n",
            "4:\tlearn: 0.1937585\ttotal: 2.84ms\tremaining: 48.3ms\n",
            "5:\tlearn: 0.1453188\ttotal: 3.18ms\tremaining: 44.6ms\n",
            "6:\tlearn: 0.1089891\ttotal: 3.51ms\tremaining: 41.6ms\n",
            "7:\tlearn: 0.0817419\ttotal: 3.82ms\tremaining: 39.2ms\n",
            "8:\tlearn: 0.0613064\ttotal: 4.14ms\tremaining: 37.3ms\n",
            "9:\tlearn: 0.0459798\ttotal: 4.43ms\tremaining: 35.5ms\n",
            "10:\tlearn: 0.0344848\ttotal: 4.74ms\tremaining: 34.1ms\n",
            "11:\tlearn: 0.0258636\ttotal: 5.07ms\tremaining: 32.9ms\n",
            "12:\tlearn: 0.0193977\ttotal: 5.38ms\tremaining: 31.9ms\n",
            "13:\tlearn: 0.0145483\ttotal: 5.69ms\tremaining: 30.9ms\n",
            "14:\tlearn: 0.0109112\ttotal: 5.99ms\tremaining: 29.9ms\n",
            "15:\tlearn: 0.0081834\ttotal: 6.31ms\tremaining: 29.2ms\n",
            "16:\tlearn: 0.0061376\ttotal: 6.62ms\tremaining: 28.4ms\n",
            "17:\tlearn: 0.0046032\ttotal: 6.94ms\tremaining: 27.8ms\n",
            "18:\tlearn: 0.0034524\ttotal: 7.25ms\tremaining: 27.1ms\n",
            "19:\tlearn: 0.0025893\ttotal: 7.58ms\tremaining: 26.5ms\n",
            "20:\tlearn: 0.0019420\ttotal: 7.9ms\tremaining: 26ms\n",
            "21:\tlearn: 0.0014565\ttotal: 8.21ms\tremaining: 25.4ms\n",
            "22:\tlearn: 0.0010924\ttotal: 8.61ms\tremaining: 25.1ms\n",
            "23:\tlearn: 0.0008193\ttotal: 8.91ms\tremaining: 24.5ms\n",
            "24:\tlearn: 0.0006144\ttotal: 9.21ms\tremaining: 24ms\n",
            "25:\tlearn: 0.0004608\ttotal: 9.51ms\tremaining: 23.4ms\n",
            "26:\tlearn: 0.0003456\ttotal: 9.82ms\tremaining: 22.9ms\n",
            "27:\tlearn: 0.0002592\ttotal: 10.1ms\tremaining: 22.4ms\n",
            "28:\tlearn: 0.0001944\ttotal: 10.6ms\tremaining: 22.4ms\n",
            "29:\tlearn: 0.0001458\ttotal: 11ms\tremaining: 22ms\n",
            "30:\tlearn: 0.0001094\ttotal: 11.3ms\tremaining: 21.6ms\n",
            "31:\tlearn: 0.0000820\ttotal: 11.7ms\tremaining: 21.1ms\n",
            "32:\tlearn: 0.0000615\ttotal: 12ms\tremaining: 20.7ms\n",
            "33:\tlearn: 0.0000461\ttotal: 12.4ms\tremaining: 20.4ms\n",
            "34:\tlearn: 0.0000346\ttotal: 12.7ms\tremaining: 20ms\n",
            "35:\tlearn: 0.0000260\ttotal: 13ms\tremaining: 19.5ms\n",
            "36:\tlearn: 0.0000195\ttotal: 13.4ms\tremaining: 19.1ms\n",
            "37:\tlearn: 0.0000146\ttotal: 13.7ms\tremaining: 18.7ms\n",
            "38:\tlearn: 0.0000109\ttotal: 14.1ms\tremaining: 18.5ms\n",
            "39:\tlearn: 0.0000082\ttotal: 14.5ms\tremaining: 18.2ms\n",
            "40:\tlearn: 0.0000062\ttotal: 15ms\tremaining: 18ms\n",
            "41:\tlearn: 0.0000046\ttotal: 15.6ms\tremaining: 17.8ms\n",
            "42:\tlearn: 0.0000035\ttotal: 15.9ms\tremaining: 17.4ms\n",
            "43:\tlearn: 0.0000026\ttotal: 16.2ms\tremaining: 16.9ms\n",
            "44:\tlearn: 0.0000019\ttotal: 16.5ms\tremaining: 16.5ms\n",
            "45:\tlearn: 0.0000015\ttotal: 16.9ms\tremaining: 16.1ms\n",
            "46:\tlearn: 0.0000011\ttotal: 17.2ms\tremaining: 15.7ms\n",
            "47:\tlearn: 0.0000008\ttotal: 17.5ms\tremaining: 15.3ms\n",
            "48:\tlearn: 0.0000006\ttotal: 17.8ms\tremaining: 14.9ms\n",
            "49:\tlearn: 0.0000005\ttotal: 18.1ms\tremaining: 14.5ms\n",
            "50:\tlearn: 0.0000003\ttotal: 18.4ms\tremaining: 14.1ms\n",
            "51:\tlearn: 0.0000003\ttotal: 18.7ms\tremaining: 13.7ms\n",
            "52:\tlearn: 0.0000002\ttotal: 19ms\tremaining: 13.3ms\n",
            "53:\tlearn: 0.0000001\ttotal: 19.3ms\tremaining: 12.9ms\n",
            "54:\tlearn: 0.0000001\ttotal: 19.6ms\tremaining: 12.5ms\n",
            "55:\tlearn: 0.0000001\ttotal: 20ms\tremaining: 12.1ms\n",
            "56:\tlearn: 0.0000001\ttotal: 20.3ms\tremaining: 11.7ms\n",
            "57:\tlearn: 0.0000000\ttotal: 20.6ms\tremaining: 11.3ms\n",
            "58:\tlearn: 0.0000000\ttotal: 20.9ms\tremaining: 11ms\n",
            "59:\tlearn: 0.0000000\ttotal: 21.2ms\tremaining: 10.6ms\n",
            "60:\tlearn: 0.0000000\ttotal: 21.5ms\tremaining: 10.2ms\n",
            "61:\tlearn: 0.0000000\ttotal: 21.8ms\tremaining: 9.85ms\n",
            "62:\tlearn: 0.0000000\ttotal: 22.1ms\tremaining: 9.47ms\n",
            "63:\tlearn: 0.0000000\ttotal: 22.4ms\tremaining: 9.11ms\n",
            "64:\tlearn: 0.0000000\ttotal: 22.9ms\tremaining: 8.81ms\n",
            "65:\tlearn: 0.0000000\ttotal: 23.3ms\tremaining: 8.46ms\n",
            "66:\tlearn: 0.0000000\ttotal: 23.6ms\tremaining: 8.1ms\n",
            "67:\tlearn: 0.0000000\ttotal: 24ms\tremaining: 7.75ms\n",
            "68:\tlearn: 0.0000000\ttotal: 24.3ms\tremaining: 7.39ms\n",
            "69:\tlearn: 0.0000000\ttotal: 24.6ms\tremaining: 7.03ms\n",
            "70:\tlearn: 0.0000000\ttotal: 24.9ms\tremaining: 6.67ms\n",
            "71:\tlearn: 0.0000000\ttotal: 25.2ms\tremaining: 6.31ms\n",
            "72:\tlearn: 0.0000000\ttotal: 25.6ms\tremaining: 5.95ms\n",
            "73:\tlearn: 0.0000000\ttotal: 25.9ms\tremaining: 5.59ms\n",
            "74:\tlearn: 0.0000000\ttotal: 26.2ms\tremaining: 5.24ms\n",
            "75:\tlearn: 0.0000000\ttotal: 26.5ms\tremaining: 4.88ms\n",
            "76:\tlearn: 0.0000000\ttotal: 26.8ms\tremaining: 4.53ms\n",
            "77:\tlearn: 0.0000000\ttotal: 27.1ms\tremaining: 4.17ms\n",
            "78:\tlearn: 0.0000000\ttotal: 27.5ms\tremaining: 3.83ms\n",
            "79:\tlearn: 0.0000000\ttotal: 27.9ms\tremaining: 3.48ms\n",
            "80:\tlearn: 0.0000000\ttotal: 28ms\tremaining: 3.11ms\n",
            "81:\tlearn: 0.0000000\ttotal: 28.3ms\tremaining: 2.76ms\n",
            "82:\tlearn: 0.0000000\ttotal: 28.6ms\tremaining: 2.41ms\n",
            "83:\tlearn: 0.0000000\ttotal: 28.9ms\tremaining: 2.06ms\n",
            "84:\tlearn: 0.0000000\ttotal: 29.2ms\tremaining: 1.72ms\n",
            "85:\tlearn: 0.0000000\ttotal: 29.5ms\tremaining: 1.37ms\n",
            "86:\tlearn: 0.0000000\ttotal: 29.8ms\tremaining: 1.03ms\n",
            "87:\tlearn: 0.0000000\ttotal: 30.1ms\tremaining: 684us\n",
            "88:\tlearn: 0.0000000\ttotal: 30.4ms\tremaining: 341us\n",
            "89:\tlearn: 0.0000000\ttotal: 30.7ms\tremaining: 0us\n",
            "[3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [30, 40, 50, 60]]\n",
        "eval_data = [[30, 50, 55, 56]]\n",
        "\n",
        "train_labels = [1,2 , 3]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=70,\n",
        "                          learning_rate=1,\n",
        "                          depth=4)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Lv5TLTsN0w8",
        "outputId": "2c241396-0b21-49fe-ee55-ee7ab9fd66b2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 184us\tremaining: 12.7ms\n",
            "1:\tlearn: 0.4592793\ttotal: 333us\tremaining: 11.3ms\n",
            "2:\tlearn: 0.3444595\ttotal: 448us\tremaining: 10ms\n",
            "3:\tlearn: 0.2583446\ttotal: 551us\tremaining: 9.1ms\n",
            "4:\tlearn: 0.1937585\ttotal: 655us\tremaining: 8.52ms\n",
            "5:\tlearn: 0.1453188\ttotal: 753us\tremaining: 8.04ms\n",
            "6:\tlearn: 0.1089891\ttotal: 851us\tremaining: 7.67ms\n",
            "7:\tlearn: 0.0817419\ttotal: 948us\tremaining: 7.35ms\n",
            "8:\tlearn: 0.0613064\ttotal: 1.07ms\tremaining: 7.24ms\n",
            "9:\tlearn: 0.0459798\ttotal: 1.17ms\tremaining: 7.03ms\n",
            "10:\tlearn: 0.0344848\ttotal: 1.27ms\tremaining: 6.81ms\n",
            "11:\tlearn: 0.0258636\ttotal: 1.36ms\tremaining: 6.6ms\n",
            "12:\tlearn: 0.0193977\ttotal: 1.47ms\tremaining: 6.46ms\n",
            "13:\tlearn: 0.0145483\ttotal: 1.56ms\tremaining: 6.26ms\n",
            "14:\tlearn: 0.0109112\ttotal: 1.66ms\tremaining: 6.08ms\n",
            "15:\tlearn: 0.0081834\ttotal: 1.76ms\tremaining: 5.94ms\n",
            "16:\tlearn: 0.0061376\ttotal: 1.85ms\tremaining: 5.78ms\n",
            "17:\tlearn: 0.0046032\ttotal: 1.96ms\tremaining: 5.65ms\n",
            "18:\tlearn: 0.0034524\ttotal: 2.05ms\tremaining: 5.5ms\n",
            "19:\tlearn: 0.0025893\ttotal: 2.14ms\tremaining: 5.35ms\n",
            "20:\tlearn: 0.0019420\ttotal: 2.23ms\tremaining: 5.21ms\n",
            "21:\tlearn: 0.0014565\ttotal: 2.32ms\tremaining: 5.07ms\n",
            "22:\tlearn: 0.0010924\ttotal: 2.41ms\tremaining: 4.93ms\n",
            "23:\tlearn: 0.0008193\ttotal: 2.5ms\tremaining: 4.8ms\n",
            "24:\tlearn: 0.0006144\ttotal: 2.6ms\tremaining: 4.67ms\n",
            "25:\tlearn: 0.0004608\ttotal: 2.69ms\tremaining: 4.55ms\n",
            "26:\tlearn: 0.0003456\ttotal: 2.78ms\tremaining: 4.42ms\n",
            "27:\tlearn: 0.0002592\ttotal: 2.87ms\tremaining: 4.3ms\n",
            "28:\tlearn: 0.0001944\ttotal: 2.99ms\tremaining: 4.23ms\n",
            "29:\tlearn: 0.0001458\ttotal: 3.09ms\tremaining: 4.12ms\n",
            "30:\tlearn: 0.0001094\ttotal: 3.19ms\tremaining: 4.01ms\n",
            "31:\tlearn: 0.0000820\ttotal: 3.3ms\tremaining: 3.91ms\n",
            "32:\tlearn: 0.0000615\ttotal: 3.4ms\tremaining: 3.81ms\n",
            "33:\tlearn: 0.0000461\ttotal: 3.51ms\tremaining: 3.72ms\n",
            "34:\tlearn: 0.0000346\ttotal: 3.63ms\tremaining: 3.63ms\n",
            "35:\tlearn: 0.0000260\ttotal: 3.75ms\tremaining: 3.54ms\n",
            "36:\tlearn: 0.0000195\ttotal: 3.85ms\tremaining: 3.43ms\n",
            "37:\tlearn: 0.0000146\ttotal: 3.94ms\tremaining: 3.32ms\n",
            "38:\tlearn: 0.0000109\ttotal: 4.05ms\tremaining: 3.22ms\n",
            "39:\tlearn: 0.0000082\ttotal: 4.15ms\tremaining: 3.12ms\n",
            "40:\tlearn: 0.0000062\ttotal: 4.25ms\tremaining: 3ms\n",
            "41:\tlearn: 0.0000046\ttotal: 4.34ms\tremaining: 2.89ms\n",
            "42:\tlearn: 0.0000035\ttotal: 4.43ms\tremaining: 2.78ms\n",
            "43:\tlearn: 0.0000026\ttotal: 4.53ms\tremaining: 2.67ms\n",
            "44:\tlearn: 0.0000019\ttotal: 4.83ms\tremaining: 2.69ms\n",
            "45:\tlearn: 0.0000015\ttotal: 5.13ms\tremaining: 2.68ms\n",
            "46:\tlearn: 0.0000011\ttotal: 5.45ms\tremaining: 2.67ms\n",
            "47:\tlearn: 0.0000008\ttotal: 6.03ms\tremaining: 2.76ms\n",
            "48:\tlearn: 0.0000006\ttotal: 6.37ms\tremaining: 2.73ms\n",
            "49:\tlearn: 0.0000005\ttotal: 6.71ms\tremaining: 2.68ms\n",
            "50:\tlearn: 0.0000003\ttotal: 7.05ms\tremaining: 2.63ms\n",
            "51:\tlearn: 0.0000003\ttotal: 7.35ms\tremaining: 2.54ms\n",
            "52:\tlearn: 0.0000002\ttotal: 7.67ms\tremaining: 2.46ms\n",
            "53:\tlearn: 0.0000001\ttotal: 7.77ms\tremaining: 2.3ms\n",
            "54:\tlearn: 0.0000001\ttotal: 8.08ms\tremaining: 2.2ms\n",
            "55:\tlearn: 0.0000001\ttotal: 8.37ms\tremaining: 2.09ms\n",
            "56:\tlearn: 0.0000001\ttotal: 8.67ms\tremaining: 1.98ms\n",
            "57:\tlearn: 0.0000000\ttotal: 8.97ms\tremaining: 1.86ms\n",
            "58:\tlearn: 0.0000000\ttotal: 9.27ms\tremaining: 1.73ms\n",
            "59:\tlearn: 0.0000000\ttotal: 9.72ms\tremaining: 1.62ms\n",
            "60:\tlearn: 0.0000000\ttotal: 10.1ms\tremaining: 1.49ms\n",
            "61:\tlearn: 0.0000000\ttotal: 10.5ms\tremaining: 1.35ms\n",
            "62:\tlearn: 0.0000000\ttotal: 10.8ms\tremaining: 1.2ms\n",
            "63:\tlearn: 0.0000000\ttotal: 11.2ms\tremaining: 1.05ms\n",
            "64:\tlearn: 0.0000000\ttotal: 11.6ms\tremaining: 890us\n",
            "65:\tlearn: 0.0000000\ttotal: 11.9ms\tremaining: 721us\n",
            "66:\tlearn: 0.0000000\ttotal: 12.2ms\tremaining: 546us\n",
            "67:\tlearn: 0.0000000\ttotal: 12.5ms\tremaining: 368us\n",
            "68:\tlearn: 0.0000000\ttotal: 12.9ms\tremaining: 186us\n",
            "69:\tlearn: 0.0000000\ttotal: 13.2ms\tremaining: 0us\n",
            "[3.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = [[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [9, 12, 15, 18]]\n",
        "eval_data = [[4, 5, 6, 7],\n",
        "             [8, 10, 12, 14]]\n",
        "\n",
        "train_labels = [-1,0 , 1]\n",
        "# Initialize CatBoostRegressor\n",
        "model = CatBoostRegressor(iterations=30,\n",
        "                          learning_rate=1,\n",
        "                          depth=2)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels)\n",
        "# Get predictions\n",
        "preds = model.predict(eval_data)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEYOHz_hOSXp",
        "outputId": "534cd42d-6e11-4f9b-a7e0-41f5d1eba626"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.6123724\ttotal: 146us\tremaining: 4.25ms\n",
            "1:\tlearn: 0.4592793\ttotal: 543us\tremaining: 7.61ms\n",
            "2:\tlearn: 0.3620013\ttotal: 876us\tremaining: 7.89ms\n",
            "3:\tlearn: 0.2665601\ttotal: 1.22ms\tremaining: 7.95ms\n",
            "4:\tlearn: 0.1999201\ttotal: 1.55ms\tremaining: 7.73ms\n",
            "5:\tlearn: 0.1499401\ttotal: 1.84ms\tremaining: 7.38ms\n",
            "6:\tlearn: 0.1124551\ttotal: 2.18ms\tremaining: 7.18ms\n",
            "7:\tlearn: 0.0843413\ttotal: 2.29ms\tremaining: 6.3ms\n",
            "8:\tlearn: 0.0632560\ttotal: 2.64ms\tremaining: 6.16ms\n",
            "9:\tlearn: 0.0474420\ttotal: 3ms\tremaining: 6ms\n",
            "10:\tlearn: 0.0355815\ttotal: 3.33ms\tremaining: 5.75ms\n",
            "11:\tlearn: 0.0266861\ttotal: 3.62ms\tremaining: 5.43ms\n",
            "12:\tlearn: 0.0200146\ttotal: 3.9ms\tremaining: 5.1ms\n",
            "13:\tlearn: 0.0150109\ttotal: 4.17ms\tremaining: 4.77ms\n",
            "14:\tlearn: 0.0112582\ttotal: 4.46ms\tremaining: 4.46ms\n",
            "15:\tlearn: 0.0084437\ttotal: 4.76ms\tremaining: 4.16ms\n",
            "16:\tlearn: 0.0063327\ttotal: 5.04ms\tremaining: 3.85ms\n",
            "17:\tlearn: 0.0047496\ttotal: 5.32ms\tremaining: 3.54ms\n",
            "18:\tlearn: 0.0035622\ttotal: 5.37ms\tremaining: 3.11ms\n",
            "19:\tlearn: 0.0026716\ttotal: 5.45ms\tremaining: 2.72ms\n",
            "20:\tlearn: 0.0020037\ttotal: 5.76ms\tremaining: 2.47ms\n",
            "21:\tlearn: 0.0015028\ttotal: 6.32ms\tremaining: 2.3ms\n",
            "22:\tlearn: 0.0011271\ttotal: 6.6ms\tremaining: 2.01ms\n",
            "23:\tlearn: 0.0008453\ttotal: 6.66ms\tremaining: 1.67ms\n",
            "24:\tlearn: 0.0006340\ttotal: 6.74ms\tremaining: 1.35ms\n",
            "25:\tlearn: 0.0004755\ttotal: 6.78ms\tremaining: 1.04ms\n",
            "26:\tlearn: 0.0003566\ttotal: 6.83ms\tremaining: 758us\n",
            "27:\tlearn: 0.0002675\ttotal: 8.02ms\tremaining: 573us\n",
            "28:\tlearn: 0.0002006\ttotal: 8.55ms\tremaining: 294us\n",
            "29:\tlearn: 0.0001504\ttotal: 8.86ms\tremaining: 0us\n",
            "[-3.17479271e-06  9.99822212e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import Pool, CatBoostClassifier\n",
        "\n",
        "train_data = [[\"summer\", 1924, 44],\n",
        "              [\"summer\", 1932, 37],\n",
        "              [\"winter\", 1980, 37],\n",
        "              [\"summer\", 2012, 204]]\n",
        "\n",
        "eval_data = [[\"winter\", 1996, 197],\n",
        "             [\"winter\", 1968, 37],\n",
        "             [\"summer\", 2002, 77],\n",
        "             [\"summer\", 1948, 59]]\n",
        "\n",
        "cat_features = [0]\n",
        "\n",
        "train_label = [\"France\", \"USA\", \"USA\", \"UK\"]\n",
        "eval_label = [\"USA\", \"France\", \"USA\", \"UK\"]\n",
        "\n",
        "\n",
        "train_dataset = Pool(data=train_data,\n",
        "                     label=train_label,\n",
        "                     cat_features=cat_features)\n",
        "\n",
        "eval_dataset = Pool(data=eval_data,\n",
        "                    label=eval_label,\n",
        "                    cat_features=cat_features)\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=70,\n",
        "                           learning_rate=1,\n",
        "                           depth=2,\n",
        "                           loss_function='MultiClass')\n",
        "# Fit model\n",
        "model.fit(train_dataset)\n",
        "# Get predicted classes\n",
        "preds_class = model.predict(eval_dataset)\n",
        "# Get predicted probabilities for each class\n",
        "preds_proba = model.predict_proba(eval_dataset)\n",
        "# Get predicted RawFormulaVal\n",
        "preds_raw = model.predict(eval_dataset, \n",
        "                          prediction_type='RawFormulaVal')\n",
        "print(preds_class)\n",
        "print(preds_proba)\n",
        "print(preds_raw)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMGkBYQPPGiz",
        "outputId": "1c2bea1c-a577-4478-b147-24a6a76dd24d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.9417331\ttotal: 333us\tremaining: 23ms\n",
            "1:\tlearn: 0.8421839\ttotal: 1.41ms\tremaining: 47.9ms\n",
            "2:\tlearn: 0.6597822\ttotal: 1.75ms\tremaining: 39.1ms\n",
            "3:\tlearn: 0.6028493\ttotal: 2.15ms\tremaining: 35.5ms\n",
            "4:\tlearn: 0.4900112\ttotal: 2.58ms\tremaining: 33.6ms\n",
            "5:\tlearn: 0.4076408\ttotal: 2.95ms\tremaining: 31.5ms\n",
            "6:\tlearn: 0.3458205\ttotal: 3.46ms\tremaining: 31.1ms\n",
            "7:\tlearn: 0.2982687\ttotal: 3.78ms\tremaining: 29.3ms\n",
            "8:\tlearn: 0.2608927\ttotal: 4.09ms\tremaining: 27.7ms\n",
            "9:\tlearn: 0.2309514\ttotal: 4.42ms\tremaining: 26.6ms\n",
            "10:\tlearn: 0.2065611\ttotal: 4.71ms\tremaining: 25.3ms\n",
            "11:\tlearn: 0.1863970\ttotal: 5.03ms\tremaining: 24.3ms\n",
            "12:\tlearn: 0.1695073\ttotal: 5.34ms\tremaining: 23.4ms\n",
            "13:\tlearn: 0.1551947\ttotal: 5.64ms\tremaining: 22.6ms\n",
            "14:\tlearn: 0.1429396\ttotal: 7.33ms\tremaining: 26.9ms\n",
            "15:\tlearn: 0.1323482\ttotal: 7.41ms\tremaining: 25ms\n",
            "16:\tlearn: 0.1246122\ttotal: 7.49ms\tremaining: 23.4ms\n",
            "17:\tlearn: 0.1163175\ttotal: 7.56ms\tremaining: 21.8ms\n",
            "18:\tlearn: 0.1089952\ttotal: 7.63ms\tremaining: 20.5ms\n",
            "19:\tlearn: 0.1024898\ttotal: 7.7ms\tremaining: 19.3ms\n",
            "20:\tlearn: 0.0976391\ttotal: 7.77ms\tremaining: 18.1ms\n",
            "21:\tlearn: 0.0923152\ttotal: 7.84ms\tremaining: 17.1ms\n",
            "22:\tlearn: 0.0875144\ttotal: 7.9ms\tremaining: 16.1ms\n",
            "23:\tlearn: 0.0831655\ttotal: 7.96ms\tremaining: 15.3ms\n",
            "24:\tlearn: 0.0792093\ttotal: 8.03ms\tremaining: 14.4ms\n",
            "25:\tlearn: 0.0755966\ttotal: 8.08ms\tremaining: 13.7ms\n",
            "26:\tlearn: 0.0722855\ttotal: 8.14ms\tremaining: 13ms\n",
            "27:\tlearn: 0.0692409\ttotal: 8.2ms\tremaining: 12.3ms\n",
            "28:\tlearn: 0.0664326\ttotal: 8.25ms\tremaining: 11.7ms\n",
            "29:\tlearn: 0.0638347\ttotal: 8.31ms\tremaining: 11.1ms\n",
            "30:\tlearn: 0.0618251\ttotal: 8.37ms\tremaining: 10.5ms\n",
            "31:\tlearn: 0.0595557\ttotal: 8.43ms\tremaining: 10ms\n",
            "32:\tlearn: 0.0574414\ttotal: 11.9ms\tremaining: 13.4ms\n",
            "33:\tlearn: 0.0554672\ttotal: 14.9ms\tremaining: 15.8ms\n",
            "34:\tlearn: 0.0536199\ttotal: 15ms\tremaining: 15ms\n",
            "35:\tlearn: 0.0518879\ttotal: 15.1ms\tremaining: 14.2ms\n",
            "36:\tlearn: 0.0502610\ttotal: 15.1ms\tremaining: 13.5ms\n",
            "37:\tlearn: 0.0487301\ttotal: 15.2ms\tremaining: 12.8ms\n",
            "38:\tlearn: 0.0472870\ttotal: 15.3ms\tremaining: 12.1ms\n",
            "39:\tlearn: 0.0461523\ttotal: 15.3ms\tremaining: 11.5ms\n",
            "40:\tlearn: 0.0448514\ttotal: 15.4ms\tremaining: 10.9ms\n",
            "41:\tlearn: 0.0438289\ttotal: 15.5ms\tremaining: 10.3ms\n",
            "42:\tlearn: 0.0426502\ttotal: 15.6ms\tremaining: 9.77ms\n",
            "43:\tlearn: 0.0415317\ttotal: 15.6ms\tremaining: 9.25ms\n",
            "44:\tlearn: 0.0404690\ttotal: 15.7ms\tremaining: 8.73ms\n",
            "45:\tlearn: 0.0394580\ttotal: 15.8ms\tremaining: 8.23ms\n",
            "46:\tlearn: 0.0384951\ttotal: 15.8ms\tremaining: 7.75ms\n",
            "47:\tlearn: 0.0375770\ttotal: 15.9ms\tremaining: 7.29ms\n",
            "48:\tlearn: 0.0367008\ttotal: 16ms\tremaining: 6.84ms\n",
            "49:\tlearn: 0.0358636\ttotal: 16ms\tremaining: 6.41ms\n",
            "50:\tlearn: 0.0350629\ttotal: 16.1ms\tremaining: 6ms\n",
            "51:\tlearn: 0.0342964\ttotal: 18.8ms\tremaining: 6.5ms\n",
            "52:\tlearn: 0.0335621\ttotal: 18.9ms\tremaining: 6.05ms\n",
            "53:\tlearn: 0.0328579\ttotal: 18.9ms\tremaining: 5.6ms\n",
            "54:\tlearn: 0.0321820\ttotal: 18.9ms\tremaining: 5.16ms\n",
            "55:\tlearn: 0.0315329\ttotal: 19ms\tremaining: 4.74ms\n",
            "56:\tlearn: 0.0309089\ttotal: 19ms\tremaining: 4.33ms\n",
            "57:\tlearn: 0.0303087\ttotal: 19ms\tremaining: 3.94ms\n",
            "58:\tlearn: 0.0297309\ttotal: 19.1ms\tremaining: 3.56ms\n",
            "59:\tlearn: 0.0291744\ttotal: 19.1ms\tremaining: 3.19ms\n",
            "60:\tlearn: 0.0286379\ttotal: 19.2ms\tremaining: 2.83ms\n",
            "61:\tlearn: 0.0281205\ttotal: 19.2ms\tremaining: 2.48ms\n",
            "62:\tlearn: 0.0276211\ttotal: 19.2ms\tremaining: 2.14ms\n",
            "63:\tlearn: 0.0272200\ttotal: 19.3ms\tremaining: 1.81ms\n",
            "64:\tlearn: 0.0267512\ttotal: 19.4ms\tremaining: 1.49ms\n",
            "65:\tlearn: 0.0263751\ttotal: 19.4ms\tremaining: 1.18ms\n",
            "66:\tlearn: 0.0259342\ttotal: 19.5ms\tremaining: 872us\n",
            "67:\tlearn: 0.0255075\ttotal: 19.5ms\tremaining: 574us\n",
            "68:\tlearn: 0.0250944\ttotal: 19.6ms\tremaining: 284us\n",
            "69:\tlearn: 0.0246943\ttotal: 21.2ms\tremaining: 0us\n",
            "[['USA']\n",
            " ['USA']\n",
            " ['UK']\n",
            " ['USA']]\n",
            "[[0.11695327 0.4096527  0.47339403]\n",
            " [0.0077033  0.00752238 0.98477432]\n",
            " [0.1590411  0.74642852 0.09453039]\n",
            " [0.33407659 0.06991911 0.59600429]]\n",
            "[[-0.88389627  0.36963896  0.51425731]\n",
            " [-1.60899951 -1.63276511  3.24176462]\n",
            " [-0.34196531  1.20417191 -0.86220661]\n",
            " [ 0.32838456 -1.2356467   0.90726214]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AUC** \n",
        "\n",
        "Area Under the Receiver Operating Characteristic (ROC) Curve (AUC) \n",
        "\n",
        "The best AUC = 1 for a model that ranks all the objects right (all objects with class 1 are assigned higher probabilities then objects of class 0). AUC for the ‘bad’ classifier which is working as random guessing is equal to 0.5."
      ],
      "metadata": {
        "id": "8d-7RjeKdWj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "train_data = [[0, 3],\n",
        "              [4, 1],\n",
        "              [8, 1],\n",
        "              [9, 1]]\n",
        "\n",
        "train_labels = [0, 0, 1, 1]\n",
        "\n",
        "eval_data = [[2, 1],\n",
        "             [3, 1],\n",
        "             [9, 0],\n",
        "             [5, 3]]\n",
        "\n",
        "eval_labels = [0, 1, 1, 0]\n",
        "\n",
        "eval_dataset = Pool(eval_data,\n",
        "                    eval_labels)\n",
        "\n",
        "model = CatBoostClassifier(learning_rate=0.03,\n",
        "                           custom_metric=['Logloss',\n",
        "                                          'AUC:hints=skip_train~false'])\n",
        "\n",
        "model.fit(train_data,\n",
        "          train_labels,\n",
        "          eval_set=eval_dataset,\n",
        "          verbose=False)\n",
        "\n",
        "print(model.get_best_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYA9FYIkdXTg",
        "outputId": "5fab1091-9f17-4fa0-c4b3-e80c1fb66b2b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learn': {'Logloss': 0.005758294697120604, 'AUC': 1.0}, 'validation': {'Logloss': 0.5366281810311608, 'AUC': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get all the parameters of the model\n",
        "\n",
        "print(model.get_all_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C88KWqQoddTT",
        "outputId": "f253022d-b0f5-4e5f-8325-a03f5d955523"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nan_mode': 'Min', 'eval_metric': 'Logloss', 'iterations': 1000, 'sampling_frequency': 'PerTree', 'leaf_estimation_method': 'Newton', 'grow_policy': 'SymmetricTree', 'penalties_coefficient': 1, 'boosting_type': 'Plain', 'model_shrink_mode': 'Constant', 'feature_border_type': 'GreedyLogSum', 'bayesian_matrix_reg': 0.10000000149011612, 'force_unit_auto_pair_weights': False, 'l2_leaf_reg': 3, 'random_strength': 1, 'rsm': 1, 'boost_from_average': False, 'model_size_reg': 0.5, 'pool_metainfo_options': {'tags': {}}, 'subsample': 1, 'use_best_model': True, 'class_names': [0, 1], 'random_seed': 0, 'depth': 6, 'posterior_sampling': False, 'border_count': 254, 'classes_count': 0, 'auto_class_weights': 'None', 'sparse_features_conflict_fraction': 0, 'custom_metric': ['Logloss', 'AUC:hints=skip_train~false'], 'leaf_estimation_backtracking': 'AnyImprovement', 'best_model_min_trees': 1, 'model_shrink_rate': 0, 'min_data_in_leaf': 1, 'loss_function': 'Logloss', 'learning_rate': 0.029999999329447743, 'score_function': 'Cosine', 'task_type': 'CPU', 'leaf_estimation_iterations': 10, 'bootstrap_type': 'MVS', 'max_leaves': 64}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class CatBoostClassifier(iterations=None,\n",
        "\n",
        "                         learning_rate=None,\n",
        "\n",
        "                         depth=None,\n",
        "\n",
        "                         l2_leaf_reg=None,\n",
        "\n",
        "                         model_size_reg=None,\n",
        "\n",
        "                         rsm=None,\n",
        "\n",
        "                         loss_function=None,\n",
        "\n",
        "                         border_count=None,\n",
        "                                                  feature_border_type=None,\n",
        "                                                                            per_float_feature_quantization=None,              \n",
        "\n",
        "                         input_borders=None,\n",
        "\n",
        "                         output_borders=None,\n",
        "                         \n",
        "                         fold_permutation_block=None,\n",
        "                         \n",
        "                         od_pval=None,\n",
        "                         \n",
        "                         od_wait=None,\n",
        "                         \n",
        "                         od_type=None,\n",
        "                         \n",
        "                         nan_mode=None,\n",
        "                         \n",
        "                         counter_calc_method=None,\n",
        "                         \n",
        "                         leaf_estimation_iterations=None,\n",
        "                         \n",
        "                         leaf_estimation_method=None,\n",
        "                         \n",
        "                         thread_count=None,\n",
        "                         \n",
        "                         random_seed=None,\n",
        "                        \n",
        "                        use_best_model=None,\n",
        "                        \n",
        "                         verbose=None,\n",
        "                        \n",
        "                         logging_level=None,\n",
        "                        \n",
        "                         metric_period=None,\n",
        "                        \n",
        "                         ctr_leaf_count_limit=None,\n",
        "                        \n",
        "                        \n",
        "                         store_all_simple_ctr=None,\n",
        "                        \n",
        "                         max_ctr_complexity=None,\n",
        "                        \n",
        "                         has_time=None,\n",
        "                        \n",
        "                         allow_const_label=None,\n",
        "                        \n",
        "                         classes_count=None,\n",
        "                        \n",
        "                         class_weights=None,\n",
        "                        \n",
        "                         one_hot_max_size=None,\n",
        "                        \n",
        "                         random_strength=None,\n",
        "                        \n",
        "                         name=None,\n",
        "                        \n",
        "                         ignored_features=None,\n",
        "                        \n",
        "                         train_dir=None,\n",
        "                        \n",
        "                         custom_loss=None,\n",
        "                        \n",
        "                         custom_metric=None,\n",
        "                        \n",
        "                         eval_metric=None,\n",
        "                        \n",
        "                         bagging_temperature=None,\n",
        "                        \n",
        "                         save_snapshot=None,\n",
        "                        \n",
        "                         snapshot_file=None,\n",
        "                        \n",
        "                         snapshot_interval=None,\n",
        "                        \n",
        "                         fold_len_multiplier=None,\n",
        "                        \n",
        "                         used_ram_limit=None,\n",
        "                        \n",
        "                         gpu_ram_part=None,\n",
        "                        \n",
        "                         allow_writing_files=None,\n",
        "                        \n",
        "                         final_ctr_computation_mode=None,\n",
        "                        \n",
        "                         approx_on_full_history=None,\n",
        "                        \n",
        "                         boosting_type=None,\n",
        "                        \n",
        "                         simple_ctr=None,\n",
        "                        \n",
        "                         combinations_ctr=None,\n",
        "                        \n",
        "                         per_feature_ctr=None,\n",
        "                        \n",
        "                         task_type=None,\n",
        "                        \n",
        "                         device_config=None,\n",
        "                        \n",
        "                         devices=None,\n",
        "                        \n",
        "                         bootstrap_type=None,\n",
        "                        \n",
        "                         subsample=None,\n",
        "                        \n",
        "                         sampling_unit=None,\n",
        "                        \n",
        "                         dev_score_calc_obj_block_size=None,\n",
        "                        \n",
        "                         max_depth=None,\n",
        "                        \n",
        "                         n_estimators=None,\n",
        "                        \n",
        "                         num_boost_round=None,\n",
        "                        \n",
        "                         num_trees=None,\n",
        "                        \n",
        "                         colsample_bylevel=None,\n",
        "                        \n",
        "                         random_state=None,\n",
        "                        \n",
        "                         reg_lambda=None,\n",
        "                        \n",
        "                         objective=None,\n",
        "                        \n",
        "                         eta=None,\n",
        "                        \n",
        "                         max_bin=None,\n",
        "                        \n",
        "                         scale_pos_weight=None,\n",
        "                        \n",
        "                         gpu_cat_features_storage=None,\n",
        "                        \n",
        "                         data_partition=None\n",
        "                        \n",
        "                         metadata=None,\n",
        "                        \n",
        "                         early_stopping_rounds=None,\n",
        "                        \n",
        "                         cat_features=None,\n",
        "                        \n",
        "                         grow_policy=None,\n",
        "                        \n",
        "                         min_data_in_leaf=None,\n",
        "                        \n",
        "                         min_child_samples=None,\n",
        "                        \n",
        "                         max_leaves=None,\n",
        "                        \n",
        "                         num_leaves=None,\n",
        "                        \n",
        "                         score_function=None,\n",
        "                        \n",
        "                         leaf_estimation_backtracking=None,\n",
        "                        \n",
        "                         ctr_history_unit=None,\n",
        "                        \n",
        "                         monotone_constraints=None,\n",
        "                        \n",
        "                         feature_weights=None,\n",
        "                        \n",
        "                         penalties_coefficient=None,\n",
        "                        \n",
        "                         first_feature_use_penalties=None,\n",
        "                        \n",
        "                         model_shrink_rate=None,\n",
        "                        \n",
        "                         model_shrink_mode=None,\n",
        "                        \n",
        "                         langevin=None,\n",
        "                        \n",
        "                         diffusion_temperature=None,\n",
        "                        \n",
        "                         posterior_sampling=None,\n",
        "                        \n",
        "                         boost_from_average=None,\n",
        "                        \n",
        "                         text_features=None,\n",
        "                        \n",
        "                         tokenizers=None,\n",
        "                        \n",
        "                         dictionaries=None,\n",
        "                        \n",
        "                         feature_calcers=None,\n",
        "                        \n",
        "                         text_processing=None)\n"
      ],
      "metadata": {
        "id": "-LWFS5UsdtNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse\n",
        "\n",
        "import catboost as cb\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "\n",
        "row = np.array([0, 0, 1, 2, 2, 2, 3, 3, 4])\n",
        "col = np.array([0, 2, 2, 0, 1, 2, 0, 2, 2])\n",
        "data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "\n",
        "X = scipy.sparse.csr_matrix((data, (row, col)), shape=(5, 3))\n",
        "print(X)\n",
        "\n",
        "y = np.array([0, 1, 0, 1, 0])\n",
        "\n",
        "dataset = cb.Pool(X, y)\n",
        "\n",
        "model = CatBoostClassifier(iterations=10)\n",
        "\n",
        "model.fit(dataset)  \n",
        "preds_class = model.predict(dataset)\n",
        "print(preds_class)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svsyKWZadswS",
        "outputId": "f698d823-bb87-4f8e-b7ff-e646dcf21f1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t1\n",
            "  (0, 2)\t2\n",
            "  (1, 2)\t3\n",
            "  (2, 0)\t4\n",
            "  (2, 1)\t5\n",
            "  (2, 2)\t6\n",
            "  (3, 0)\t7\n",
            "  (3, 2)\t8\n",
            "  (4, 2)\t9\n",
            "Learning rate set to 0.07318\n",
            "0:\tlearn: 0.6899286\ttotal: 187us\tremaining: 1.69ms\n",
            "1:\tlearn: 0.6867268\ttotal: 563us\tremaining: 2.25ms\n",
            "2:\tlearn: 0.6811826\ttotal: 930us\tremaining: 2.17ms\n",
            "3:\tlearn: 0.6757004\ttotal: 1.3ms\tremaining: 1.95ms\n",
            "4:\tlearn: 0.6724513\ttotal: 1.64ms\tremaining: 1.64ms\n",
            "5:\tlearn: 0.6713895\ttotal: 1.95ms\tremaining: 1.3ms\n",
            "6:\tlearn: 0.6703385\ttotal: 2.24ms\tremaining: 961us\n",
            "7:\tlearn: 0.6649772\ttotal: 2.58ms\tremaining: 645us\n",
            "8:\tlearn: 0.6617528\ttotal: 2.92ms\tremaining: 325us\n",
            "9:\tlearn: 0.6564871\ttotal: 3.24ms\tremaining: 0us\n",
            "[0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "# Initialize data\n",
        "cat_features = [0, 1]\n",
        "train_data = [[\"a\", \"b\", 1, 4, 5, 6],\n",
        "              [\"a\", \"b\", 4, 5, 6, 7],\n",
        "              [\"c\", \"d\", 30, 40, 50, 60]]\n",
        "train_labels = [1, 1, -1]\n",
        "eval_data = [[\"a\", \"b\", 2, 4, 6, 8],\n",
        "             [\"a\", \"d\", 1, 4, 50, 60]]\n",
        "\n",
        "# Initialize CatBoostClassifier\n",
        "model = CatBoostClassifier(iterations=2,\n",
        "                           learning_rate=1,\n",
        "                           depth=2)\n",
        "# Fit model\n",
        "model.fit(train_data, train_labels, cat_features)\n",
        "# Get predicted classes\n",
        "preds_class = model.predict(eval_data)\n",
        "print(preds_class)\n",
        "# Get predicted probabilities for each class\n",
        "preds_proba = model.predict_proba(eval_data)\n",
        "print(preds_proba)\n",
        "# Get predicted RawFormulaVal\n",
        "preds_raw = model.predict(eval_data, prediction_type='RawFormulaVal')\n",
        "print(preds_raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZv2Rc8RdzNt",
        "outputId": "1256aa98-e755-4348-8324-d8738d6cfd7d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.5799547\ttotal: 151us\tremaining: 151us\n",
            "1:\tlearn: 0.4935526\ttotal: 1.5ms\tremaining: 0us\n",
            "[1 1]\n",
            "[[0.37014499 0.62985501]\n",
            " [0.4641579  0.5358421 ]]\n",
            "[0.53159487 0.14361474]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import Pool, cv\n",
        "\n",
        "cv_data = [[\"France\", 1924, 44],\n",
        "           [\"USA\", 1932, 37],\n",
        "           [\"Switzerland\", 1928, 25],\n",
        "           [\"Norway\", 1952, 30],\n",
        "           [\"Japan\", 1972, 35],\n",
        "           [\"Mexico\", 1968, 112]]\n",
        "\n",
        "labels = [1, 1, 0, 0, 0, 1]\n",
        "\n",
        "cv_dataset = Pool(data=cv_data,\n",
        "                  label=labels,\n",
        "                  cat_features=[0])\n",
        "\n",
        "params = {\"iterations\": 2,\n",
        "          \"depth\": 2,\n",
        "          \"loss_function\": \"Logloss\",\n",
        "          \"verbose\": False,\n",
        "          \"roc_file\": \"roc-file\"}\n",
        "\n",
        "scores = cv(cv_dataset,\n",
        "            params,\n",
        "            fold_count=2)\n",
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln08-p7kd2j6",
        "outputId": "f4571efe-79bd-4aee-8fe9-d85e41672747"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on fold [0/2]\n",
            "\n",
            "bestTest = 0.6769347765\n",
            "bestIteration = 1\n",
            "\n",
            "Training on fold [1/2]\n",
            "\n",
            "bestTest = 0.693188484\n",
            "bestIteration = 0\n",
            "\n",
            "   iterations  test-Logloss-mean  test-Logloss-std  train-Logloss-mean  \\\n",
            "0           0           0.689013          0.005904            0.681549   \n",
            "1           1           0.685340          0.011887            0.660894   \n",
            "\n",
            "   train-Logloss-std  \n",
            "0           0.007307  \n",
            "1           0.001061  \n"
          ]
        }
      ]
    }
  ]
}