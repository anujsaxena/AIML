{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNhf+gr5o7zJJw/u6CWrlh0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anujsaxena/AIML/blob/main/AIML_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Artificial Intelligence – 2**\n",
        "\n",
        "# **History**\n",
        "\n",
        "Maturation of Artificial Intelligence (1943-1952)\n",
        "\n",
        "o\tYear 1943: The first work which is now recognized as AI was done by Warren McCulloch and Walter pits in 1943. They proposed a model of artificial neurons.\n",
        "\n",
        "o\tYear 1949: Donald Hebb demonstrated an updating rule for modifying the connection strength between neurons. His rule is now called Hebbian learning.\n",
        "\n",
        "o\tYear 1950: The Alan Turing who was an English mathematician and pioneered Machine learning in 1950. Alan Turing publishes \"Computing Machinery and Intelligence\" in which he proposed a test. The test can check the machine's ability to exhibit intelligent behavior equivalent to human intelligence, called a Turing test.\n",
        "\n",
        "The birth of Artificial Intelligence (1952-1956)\n",
        "\n",
        "o\tYear 1955: An Allen Newell and Herbert A. Simon created the \"first artificial intelligence program\"Which was named as \"Logic Theorist\". This program had proved 38 of 52 Mathematics theorems, and find new and more elegant proofs for some theorems.\n",
        "\n",
        "o\tYear 1956: The word \"Artificial Intelligence\" first adopted by American Computer scientist John McCarthy at the Dartmouth Conference. For the first time, AI coined as an academic field.\n",
        "At that time high-level computer languages such as FORTRAN, LISP, or COBOL were invented. And the enthusiasm for AI was very high at that time.\n",
        "The golden years-Early enthusiasm (1956-1974)\n",
        "\n",
        "o\tYear 1966: The researchers emphasized developing algorithms which can solve mathematical problems. Joseph Weizenbaum created the first chatbot in 1966, which was named as ELIZA.\n",
        "\n",
        "o\tYear 1972: The first intelligent humanoid robot was built in Japan which was named as WABOT-1.\n",
        "\n",
        "The first AI winter (1974-1980)\n",
        "\n",
        "o\tThe duration between years 1974 to 1980 was the first AI winter duration. AI winter refers to the time period where computer scientist dealt with a severe shortage of funding from government for AI researches.\n",
        "\n",
        "o\tDuring AI winters, an interest of publicity on artificial intelligence was decreased.\n",
        "\n",
        "A boom of AI (1980-1987)\n",
        "\n",
        "o\tYear 1980: After AI winter duration, AI came back with \"Expert System\". Expert systems were programmed that emulate the decision-making ability of a human expert.\n",
        "\n",
        "o\tIn the Year 1980, the first national conference of the American Association of Artificial Intelligence was held at Stanford University.\n",
        "\n",
        "The second AI winter (1987-1993)\n",
        "\n",
        "o\tThe duration between the years 1987 to 1993 was the second AI Winter duration.\n",
        "\n",
        "o\tAgain Investors and government stopped in funding for AI research as due to high cost but not efficient result. The expert system such as XCON was very cost effective.\n",
        "\n",
        "The emergence of intelligent agents (1993-2011)\n",
        "\n",
        "o\tYear 1997: In the year 1997, IBM Deep Blue beats world chess champion, Gary Kasparov, and became the first computer to beat a world chess champion.\n",
        "\n",
        "o\tYear 2002: for the first time, AI entered the home in the form of Roomba, a vacuum cleaner.\n",
        "\n",
        "o\tYear 2006: AI came in the Business world till the year 2006. Companies like Facebook, Twitter, and Netflix also started using AI.\n",
        "\n",
        "Deep learning, big data and artificial general intelligence (2011-present)\n",
        "\n",
        "o\tYear 2011: In the year 2011, IBM's Watson won jeopardy, a quiz show, where it had to solve the complex questions as well as riddles. Watson had proved that it could understand natural language and can solve tricky questions quickly.\n",
        "\n",
        "o\tYear 2012: Google has launched an Android app feature \"Google now\", which was able to provide information to the user as a prediction.\n",
        "\n",
        "o\tYear 2014: In the year 2014, Chatbot \"Eugene Goostman\" won a competition in the infamous \"Turing test.\"\n",
        "\n",
        "o\tYear 2018: The \"Project Debater\" from IBM debated on complex topics with two master debaters and also performed extremely well.\n",
        "\n",
        "o\tGoogle has demonstrated an AI program \"Duplex\" which was a virtual assistant and which had taken hairdresser appointment on call, and lady on other side didn't notice that she was talking with the machine.\n",
        "\n",
        "AI has now progressed to a phenomenal level. Deep learning, big data, and data science are all hot topics now. Companies such as Google, Facebook, IBM, and Amazon are now using AI to create incredible technologies. Artificial Intelligence's future is exciting, and it will be highly intelligent.\n"
      ],
      "metadata": {
        "id": "gGFEJ8SBuyw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Types of AI**\n",
        "\n",
        "There are four type of AI.\n",
        "\n",
        "1.\tReactive Machines\n",
        "\n",
        "A reactive machine is guided by the most fundamental AI principles and, as the name suggests, is solely capable of seeing and reacting to the environment around it. Because a reactive machine lacks memory, it cannot depend on previous experiences to guide real-time decision-making. Reactive machines are designed to do only a restricted number of specialised tasks since they see the world immediately. However, intentionally reducing a reactive machine's worldview is not a cost-cutting technique; instead, it implies that this form of AI will be more trustworthy and dependable — it will respond consistently to the same stimuli.\n",
        "\n",
        "Deep Blue, an IBM chess-playing supercomputer that defeated world expert Gary Kasparov in a game in the 1990s, is a renowned example of a reactive machine. Deep Blue could only recognise the pieces on a chess board and know how they move according to the rules of the game, as well as recognise each piece's current location and choose the best logical move at the time. The machine was not looking for future possible plays from its opponent or attempting to better place its own pieces. Every turn was treated as though it were its own world, distinct from any previous action.\n",
        "\n",
        "Google's AlphaGo is another example of a game-playing reactive computer. AlphaGo is also unable to predict future plays, instead relying on its own neural network to assess current game developments, giving it an advantage over Deep Blue in a more complex game. AlphaGo has also defeated world-class Go players, including Lee Sedol, the 2016 Go champion. Reactive machine artificial intelligence may achieve a degree of complexity and dependability when designed to accomplish recurring tasks, despite its restricted scope and inability to be readily updated.\n"
      ],
      "metadata": {
        "id": "AWimneIWy0Px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Limited Memory\n",
        "\n",
        "When gathering information and assessing prospective options, artificial intelligence with limited memory can store prior data and predictions, basically peering into the past for indications on what could happen tomorrow. Artificial intelligence with limited memory is more complicated and has more possibilities than reactive robots. Artificial intelligence with limited memory may preserve earlier facts and forecasts while gathering information and evaluating potential solutions, effectively peeking into the past for clues on what might happen tomorrow. Artificial intelligence with limited memory is more difficult than reactive robots and has more possibilities.\n",
        "\n",
        "\n",
        "There are three primary machine learning methods that use artificial intelligence with limited memory:\n",
        "\n",
        "\n",
        "•\tReinforcement learning: which learns to make better predictions through repeated trial-and-error.\n",
        "\n",
        "•\tLong Short Term Memory (LSTM): It makes use of previous data to forecast the next item in a series When generating predictions, LTSMs prioritise more current information and devalue data from the past, yet they still use it to draw inferences.\n",
        "\n",
        "•\tEvolutionary Generative Adversarial Networks (E-GAN): With each new decision, it evolves, allowing it to explore slightly changed courses depending on prior experiences. Throughout its evolutionary mutation cycle, this model is always looking for a better path and uses simulations and statistics, or chance, to anticipate outcomes.\n"
      ],
      "metadata": {
        "id": "shNDoriF2E5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Theory of Mind\n",
        "\n",
        "Theory of Mind is exactly that: a theory. We haven't yet developed the technology and scientific capabilities required to advance artificial intelligence to the next level. The concept is based on the psychological premise that other living beings have thoughts and feelings that influence one's own actions. This would mean that AI computers might understand how people, animals, and other machines feel and make decisions through self-reflection and determination, and then use that information to make their own conclusions. In order to create a two-way interaction between people and artificial intelligence, computers would need to be able to understand and interpret the idea of \"mind,\" the fluctuations of emotions in decision making, and a slew of other psychological concepts in real time.\n"
      ],
      "metadata": {
        "id": "b4tl-cL_31Tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Self-awareness\n",
        "The ultimate stage for AI to become self-aware will be to build Theory of Mind in artificial intelligence, which will happen sometime in the future. This type of artificial intelligence is conscious on a human level and is aware of its own presence in the environment as well as the presence and emotional condition of others. It would be able to deduce what others may require based on not just what they say to them, but also how they say it. In artificial intelligence, self-awareness requires both human researchers to grasp the concept of consciousness and then discover how to reproduce it so that it can be implemented into machines.\n"
      ],
      "metadata": {
        "id": "aWwpZviD4xJ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Types of Machine Learning Algorithm**\n",
        "\n",
        "# **Supervised learning**\n",
        "The machine is taught by example in supervised learning. The operator gives the machine learning algorithm a known dataset including desired inputs and outputs, and the computer must figure out how to get to those inputs and outputs. The algorithm finds patterns in data, learns from observations, and produces predictions while the operator knows the proper answers to the issue. The operator corrects the algorithm's predictions, and the process repeats until the algorithm achieves a high degree of accuracy/performance.\n",
        "\n",
        "Classification, regression, and forecasting all fall under the supervised learning.\n",
        "\n",
        "a. Classification: In classification tasks, the machine learning program must draw a conclusion from observed values and determine to what category new observations belong. For example, when filtering emails as ‘spam’ or ‘not spam’, the program must look at existing observational data and filter the emails accordingly.\n",
        "\n",
        "b. Regression: In regression tasks, the machine learning program must estimate – and understand – the relationships among variables. Regression analysis focuses on one dependent variable and a series of other changing variables making it particularly useful for prediction and forecasting.\n",
        "\n",
        "c. Forecasting: Forecasting is the process of making predictions about the future based on the past and present data, and is commonly used to analyse trends.\n"
      ],
      "metadata": {
        "id": "rsZVLGah5fHL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Semi-Supervised Learning**\n",
        "\n",
        "Semi-supervised learning is like supervised learning, except it works with both labelled and unlabelled data. Unlabelled data is information that does not have relevant tags so that the algorithm can comprehend it, whereas labelled data does. Using this combination, machine learning systems can learn to identify unlabelled data.\n"
      ],
      "metadata": {
        "id": "8PzPbLYD6KIW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Unsupervised Learning**\n",
        "\n",
        "Here, the machine learning algorithm studies data to identify patterns. There is no answer key or human operator to provide instruction. Instead, the machine determines the correlations and relationships by analysing available data. In an unsupervised learning process, the machine learning algorithm is left to interpret large data sets and address that data accordingly. The algorithm tries to organise that data in some way to describe its structure. This might mean grouping the data into clusters or arranging it in a way that looks more organised.\n",
        "\n",
        "As it assesses more data, its ability to make decisions on that data gradually improves and becomes more refined.\n",
        "Here, we have:\n",
        "\n",
        "1.\tClustering: Clustering involves grouping sets of similar data (based on defined criteria). It’s useful for segmenting data into several groups and performing analysis on each data set to find patterns.\n",
        "\n",
        "2.\tDimension reduction: Dimension reduction reduces the number of variables being considered to find the exact information required.\n"
      ],
      "metadata": {
        "id": "ufM1Bb7V6fx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reinforcement Learning**\n",
        "\n",
        "Reinforcement learning focuses on regimented learning processes, where a machine learning algorithm is provided with a set of actions, parameters and end values. By defining the rules, the machine learning algorithm then tries to explore different options and possibilities, monitoring and evaluating each result to determine which one is optimal. Reinforcement learning teaches the machine trial and error. It learns from past experiences and begins to adapt its approach in response to the situation to achieve the best possible result.\n"
      ],
      "metadata": {
        "id": "FieWEMr0655s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoV0dtwPqgfz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}